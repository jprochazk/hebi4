//! ## Safety in the VM
//!
//! The VM uses a _LOT_ of unsafe code. Too much, in fact. Some of it can likely be
//! removed without introducing performance overhead, but performance is the primary goal
//! of doing this in the first place. The usual approach of "take safe code, and sprinkle
//! in unsafe carefully to improve performance" never worked out for me. My understanding
//! for why is that it was always a death by a thousand cuts: Bounds checks, drop glue,
//! overly large types, extra allocations, runtime assertions, panic machinery, etc.
//!
//! Instead, the VM here attempts to start from a relatively clean slate. We try as much
//! as possible to reduce the chances for error by using type-safe wrappers and limiting
//! the usage of Rust references, which would require us to uphold their strong guarantees
//! everywhere.
//!
//! We're making a wild assumption: The code generated by the Hebi compiler is valid.
//! I believe that the compiler is simple enough that it's possible to comprehensively check
//! all of it. Extensive codegen and runtime tests (including fuzzing) are used to help
//! validate those assumptions.
//!
//! Assuming the compiler is indeed correct, it upholds certain invariants which we can use
//! to reduce runtime overhead in the VM.
//!
//! All accesses to the VM stack are guaranteed to be safe:
//! - The stack always has enough space for the maximum possible number of registers that
//!   a given function needs.
//! - A value on the stack is guaranteed to be initialized before it is first read.
//!
//! A concrete example of this is the `Reg` (register) newtype used to offset `Sp` (stack pointer),
//! the operation will _always_ yield a properly-aligned pointer into a memory located within bounds
//! of an allocation, removing the need for a bounds check, or dynamically growing the stack
//! on demand when writing to it.
//!
//! Not just that, but because a value in a register is never read before it's initialized,
//! we also don't need to pre-initialize the contents of the stack with default values.
//! It is allocated using `alloc_zeroed` (though technically `0` is a valid bit pattern for `Value`),
//! and then pointers to this allocation are handed out as needed.
//!
//! Taking advantage of all of this, Hebi's `mov` instruction can compile down to just:
//! - A decode of the instruction operands (two zero-extended movs from a register)
//! - The actual `mov` of the value between two memory locations
//! - A dispatch of the next instruction (a few `mov`s and a `jmp rax`)
//!
//! That's as low-overhead as it gets, which is the ultimate goal here.

mod array;

#[macro_use]
pub mod gc;

pub mod value;

use std::{marker::PhantomData, ptr::NonNull};

use array::{DynArray, DynStack};
use gc::{Gc, Heap};
use value::{List, ModuleProto, String, Table};

use crate::{
    codegen::opcodes::*,
    error::{Error, Result, error},
    module,
    span::Span,
    vm::value::{FunctionProto, ValueRaw, module::ModuleRegistry},
};

impl Sp {
    #[inline(always)]
    pub unsafe fn at(self, r: Reg) -> *mut ValueRaw {
        self.0.offset(r.sz()).as_ptr()
    }
}

trait LpIdx {
    fn idx(self) -> isize;
}

impl LpIdx for Lit {
    #[inline(always)]
    fn idx(self) -> isize {
        self.sz()
    }
}

impl LpIdx for Lit8 {
    #[inline(always)]
    fn idx(self) -> isize {
        self.sz()
    }
}

impl Lp {
    #[inline]
    fn from_fn(f: Gc<FunctionProto>) -> Self {
        unsafe {
            let ptr = f.as_ref().literals().as_ptr().cast_mut();
            Self(NonNull::new_unchecked(ptr))
        }
    }

    #[inline(always)]
    unsafe fn _at(self, r: isize) -> *const ValueRaw {
        self.0.offset(r).as_ptr()
    }

    // note: these use pointer reads to avoid matching with an `unreachable` branch,
    // which for some reason still generat branches
    // TODO: could be made safer with some kind of enum `offset_of`

    #[inline(always)]
    pub unsafe fn int_or_float_unchecked(self, r: impl LpIdx) -> ValueRaw {
        let v = self._at(r.idx());

        debug_assert!(matches!(&*v, ValueRaw::Int(..) | ValueRaw::Float(..)));
        v.cast::<ValueRaw>().read()
    }

    #[inline(always)]
    pub unsafe fn int_unchecked(self, r: impl LpIdx) -> i64 {
        let v = self._at(r.idx());

        debug_assert!(matches!(&*v, ValueRaw::Int(..)));
        v.cast::<u64>().add(1).cast::<i64>().read()
    }

    #[inline(always)]
    pub unsafe fn float_unchecked(self, r: impl LpIdx) -> f64 {
        let v = self._at(r.idx());

        debug_assert!(matches!(&*v, ValueRaw::Float(..)));
        v.cast::<u64>().add(1).cast::<f64>().read()
    }

    #[inline(always)]
    pub unsafe fn str_unchecked(self, r: impl LpIdx) -> Gc<String> {
        let v = self._at(r.idx());

        debug_assert!(matches!(&*v, ValueRaw::String(..)));
        v.cast::<u64>().add(1).cast::<Gc<String>>().read()
    }
}

impl Jt {
    #[inline(always)]
    pub unsafe fn at(self, insn: Insn) -> OpaqueHandler {
        self.0.offset(insn.tag()).read()
    }
}

impl Ip {
    #[inline]
    fn from_fn(f: Gc<FunctionProto>) -> Self {
        unsafe {
            let ptr = f.as_mut().code_mut().as_mut_ptr();
            Self(NonNull::new_unchecked(ptr))
        }
    }

    #[inline]
    unsafe fn offset_from_unsigned(self, other: Self) -> usize {
        (self.0).offset_from_unsigned(other.0)
    }

    #[inline]
    unsafe fn offset(self, n: isize) -> Self {
        Ip((self.0).offset(n as isize))
    }

    #[inline(always)]
    unsafe fn next(self) -> Self {
        Self(self.0.offset(1))
    }

    #[inline(always)]
    unsafe fn get(self) -> Insn {
        self.0.read()
    }
}

#[derive(Clone, Copy)]
struct CallFrame {
    callee: Gc<FunctionProto>,

    /// Stack base of _this_ frame.
    stack_base: u32,

    /// Address of the next instruction to execute
    /// after returning from _this_ call frame.
    ///
    /// Points into the previous call frame's callee,
    /// if there is one.
    return_addr: u32,
}

#[derive(Clone, Copy)]
struct CallFramePtr(*mut CallFrame);

impl CallFramePtr {
    #[inline]
    unsafe fn raw(self) -> *mut CallFrame {
        self.0
    }

    #[inline]
    unsafe fn callee(self) -> Gc<FunctionProto> {
        (*self.0).callee
    }

    #[inline]
    unsafe fn stack_base(self) -> u32 {
        (*self.0).stack_base
    }

    #[inline]
    unsafe fn return_addr(self) -> u32 {
        (*self.0).return_addr
    }
}

impl Vm {
    #[inline]
    unsafe fn current_frame(self) -> CallFramePtr {
        // for the code below to be safe, this must be true:
        const _: () =
            assert!(core::mem::size_of::<Option<CallFrame>>() == core::mem::size_of::<CallFrame>());

        let ptr = &raw mut (*self.0.as_ptr()).current_frame;
        let ptr = ptr.cast::<CallFrame>();
        CallFramePtr(ptr)
    }

    #[inline]
    unsafe fn push_frame(self, frame: CallFrame) {
        let frames = &mut (*self.0.as_ptr()).frames;
        frames.push(frame);
    }

    #[inline]
    unsafe fn pop_frame_unchecked(self) -> CallFrame {
        let frames = &mut (*self.0.as_ptr()).frames;
        frames.pop_unchecked()
    }

    #[inline]
    unsafe fn has_enough_stack_space(self, stack_base: usize, nstack: usize) -> bool {
        let stack = &mut (*self.0.as_ptr()).stack;
        let remaining = stack.remaining(stack_base);
        remaining >= (nstack as isize)
    }

    #[inline]
    unsafe fn stack_at(self, stack_base: usize) -> Sp {
        let stack = &mut (*self.0.as_ptr()).stack;
        Sp(NonNull::new_unchecked(stack.offset(stack_base)))
    }

    #[inline]
    unsafe fn grow_stack(self, additional: usize) {
        let stack = &mut (*self.0.as_ptr()).stack;
        stack.grow(additional)
    }

    #[inline]
    unsafe fn get_function_in_current_module(self, id: FnId) -> Gc<FunctionProto> {
        self.current_module()
            .as_ref()
            .get_function_unchecked(id)
            .as_ptr()
    }

    #[inline]
    unsafe fn current_module(self) -> Gc<ModuleProto> {
        (*self.0.as_ptr()).current_module.unwrap_unchecked()
    }

    #[inline]
    unsafe fn set_current_module_for(self, f: Gc<FunctionProto>) {
        let module = f.as_ref().module().as_ptr();
        (*self.0.as_ptr()).current_module = Some(module);
    }

    #[inline]
    unsafe fn write_error(self, error: Error) {
        (*self.0.as_ptr()).error = Some(error);
    }

    #[inline]
    unsafe fn take_error(mut self) -> Option<Error> {
        self.0.as_mut().error.take()
    }

    #[inline]
    unsafe fn get_span(self, ip: Ip) -> Option<Span> {
        let pc = ip.offset_from_unsigned(Ip::from_fn(self.current_frame().callee()));
        match self.current_frame().callee().as_ref().dbg() {
            Some(dbg) => Some(dbg.spans[pc]),
            None => None,
        }
    }

    #[inline]
    unsafe fn set_saved_ip(self, ip: Ip) {
        let ptr = &raw mut (*self.0.as_ptr()).saved_ip;
        ptr.write(Some(ip));
    }

    #[inline]
    unsafe fn saved_ip(self) -> Option<Ip> {
        (*self.0.as_ptr()).saved_ip
    }

    #[inline]
    unsafe fn get_span_for_saved_ip(self) -> Option<Span> {
        let ip = self.saved_ip()?;
        self.get_span(ip)
    }

    #[inline]
    unsafe fn heap(self) -> *mut Heap {
        &raw mut (*self.0.as_ptr()).heap
    }

    #[inline]
    unsafe fn maybe_gc(self) {
        // TODO: GC thresholds
        // for now, we always GC

        self.full_gc();
    }

    #[cold]
    unsafe fn full_gc(self) {
        let heap = &raw mut (*self.0.as_ptr()).heap;
        let roots = VmRoots { state: self.0 };
        Heap::collect_with_external_roots(heap, roots);
    }
}

#[derive(Clone, Copy)]
#[repr(u8)]
pub enum VmError {
    DivisionByZero,
    ArithTypeError,
    UnopInvalidType,
    CmpTypeError,
    NotAList,
    InvalidArrayIndex,
    IndexOutOfBounds,
    NotATable,
    InvalidTableKey,
}

impl VmError {
    // NOTE: assumes `vm.saved_ip` is set
    unsafe fn annotate(&self, vm: Vm) -> Error {
        let span = vm.get_span_for_saved_ip().unwrap_or_default();
        match self {
            Self::DivisionByZero => error("division by zero", span),
            Self::ArithTypeError => error("type mismatch", span),
            Self::UnopInvalidType => error("invalid type", span),
            Self::CmpTypeError => error("type mismatch", span),
            Self::NotAList => error("not a list", span),
            Self::InvalidArrayIndex => error("value is not a valid array index", span),
            Self::IndexOutOfBounds => error("index out of bounds", span),
            Self::NotATable => error("not a table", span),
            Self::InvalidTableKey => error("value is not a valid table key", span),
        }
    }

    #[inline]
    fn is_external(self) -> bool {
        match self {
            Self::DivisionByZero
            | Self::ArithTypeError
            | Self::UnopInvalidType
            | Self::CmpTypeError
            | Self::NotAList
            | Self::InvalidArrayIndex
            | Self::IndexOutOfBounds
            | Self::NotATable
            | Self::InvalidTableKey => false,
        }
    }
}

macro_rules! vm_exit {
    ($vm:ident, $ip:ident, $error:ident) => {{
        $vm.set_saved_ip($ip);
        return Control::error(VmError::$error);
    }};
}

static JT: JumpTable = jump_table! {
    nop,
    mov,

    lmvar,
    smvar,
    lcap,
    scap,
    lidx,
    lidxn,
    sidx,
    sidxn,
    lkey,
    lkeyc,
    skey,
    skeyc,

    lnil,
    lsmi,
    ltrue,
    lfalse,
    lint,
    lnum,
    lstr,
    lclosure,
    lfunc,
    llist,
    ltable,
    jmp,
    istrue,
    istruec,
    isfalse,
    isfalsec,
    islt,
    isle,
    isgt,
    isge,
    iseq,
    isne,
    iseqs,
    isnes,
    iseqn,
    isnen,
    iseqp,
    isnep,
    isltv,
    islev,
    isgtv,
    isgev,
    iseqv,
    isnev,
    addvv,
    addvn,
    addnv,
    subvv,
    subvn,
    subnv,
    mulvv,
    mulvn,
    mulnv,
    divvv,
    divvn,
    divnv,
    unm,
    not,
    call,
    fastcall,
    ret,
    stop,
};

#[cfg(not(debug_assertions))]
#[derive(Clone, Copy)]
#[repr(transparent)]
pub(crate) struct Control(u8);

#[cfg(not(debug_assertions))]
impl Control {
    #[inline]
    fn stop() -> Control {
        Control(0)
    }

    #[inline]
    fn error(code: VmError) -> Control {
        Control(1 & ((code as u8) << 1))
    }

    #[inline]
    fn is_stop(self) -> bool {
        self.0 == 0
    }

    #[inline]
    fn is_error(self) -> bool {
        self.0 & 1 == 1
    }

    #[inline]
    unsafe fn error_code(self) -> VmError {
        core::mem::transmute(self.0 >> 1)
    }
}

#[cfg(debug_assertions)]
#[derive(Clone, Copy)]
#[repr(C)]
pub(crate) enum Control {
    Stop,
    Error(VmError),
    Continue(Sp, Lp, Ip),
}

#[cfg(debug_assertions)]
impl Control {
    #[inline]
    fn stop() -> Control {
        Control::Stop
    }

    #[inline]
    fn error(code: VmError) -> Control {
        Control::Error(code)
    }
}

/// Dispatch instruction at `ip`
#[inline(always)]
unsafe fn dispatch_current(vm: Vm, jt: Jt, ip: Ip, sp: Sp, lp: Lp) -> Control {
    #[cfg(debug_assertions)]
    {
        Control::Continue(sp, lp, ip)
    }

    #[cfg(not(debug_assertions))]
    {
        let insn = ip.get();
        let op = jt.at(insn);
        op(vm, jt, ip, insn, sp, lp)
    }
}

/// Dispatch instruction at `ip+1`
#[inline(always)]
unsafe fn dispatch_next(vm: Vm, jt: Jt, ip: Ip, sp: Sp, lp: Lp) -> Control {
    let ip = ip.next();
    dispatch_current(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn nop(vm: Vm, jt: Jt, ip: Ip, args: Nop, sp: Sp, lp: Lp) -> Control {
    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn mov(vm: Vm, jt: Jt, ip: Ip, args: Mov, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = *sp.at(args.src());

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lmvar(vm: Vm, jt: Jt, ip: Ip, args: Lmvar, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn smvar(vm: Vm, jt: Jt, ip: Ip, args: Smvar, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn lcap(vm: Vm, jt: Jt, ip: Ip, args: Lcap, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn scap(vm: Vm, jt: Jt, ip: Ip, args: Scap, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn lidx(vm: Vm, jt: Jt, ip: Ip, args: Lidx, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn lidxn(vm: Vm, jt: Jt, ip: Ip, args: Lidxn, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn sidx(vm: Vm, jt: Jt, ip: Ip, args: Sidx, sp: Sp, lp: Lp) -> Control {
    let target = *sp.at(args.target());
    let idx = *sp.at(args.idx());
    let src = *sp.at(args.src());

    let ValueRaw::List(list) = target else {
        return not_a_list_error(ip, vm);
    };

    let ValueRaw::Int(idx) = idx else {
        return invalid_array_index_error(ip, vm);
    };
    let idx = idx as usize;

    // UNROOTED: reachable through the stack
    let len = list.as_ref().len();
    if idx >= len {
        return index_out_of_bounds_error(ip, vm);
    }

    list.as_mut().set_raw_unchecked(idx, src);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[cold]
unsafe fn invalid_array_index_error(ip: Ip, vm: Vm) -> Control {
    vm_exit!(vm, ip, InvalidArrayIndex);
}

#[inline(always)]
unsafe fn sidxn(vm: Vm, jt: Jt, ip: Ip, args: Sidxn, sp: Sp, lp: Lp) -> Control {
    let idx = lp.int_unchecked(args.idx()) as usize;
    let list = *sp.at(args.target());
    let src = *sp.at(args.src());

    let ValueRaw::List(list) = list else {
        return not_a_list_error(ip, vm);
    };

    // UNROOTED: reachable through the stack
    let len = list.as_ref().len();
    if idx >= len {
        return index_out_of_bounds_error(ip, vm);
    }

    list.as_mut().set_raw_unchecked(idx, src);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[cold]
unsafe fn not_a_list_error(ip: Ip, vm: Vm) -> Control {
    vm_exit!(vm, ip, NotAList);
}

#[cold]
unsafe fn index_out_of_bounds_error(ip: Ip, vm: Vm) -> Control {
    vm_exit!(vm, ip, IndexOutOfBounds);
}

#[inline(always)]
unsafe fn lkey(vm: Vm, jt: Jt, ip: Ip, args: Lkey, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn lkeyc(vm: Vm, jt: Jt, ip: Ip, args: Lkeyc, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn skey(vm: Vm, jt: Jt, ip: Ip, args: Skey, sp: Sp, lp: Lp) -> Control {
    let target = *sp.at(args.target());
    let key = *sp.at(args.key());
    let src = *sp.at(args.src());

    let ValueRaw::Table(table) = target else {
        return not_a_table_error(ip, vm);
    };

    let ValueRaw::String(key) = key else {
        return invalid_table_key_error(ip, vm);
    };

    // UNROOTED: reachable through the stack
    table.as_mut().insert_raw(key, src);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[cold]
unsafe fn not_a_table_error(ip: Ip, vm: Vm) -> Control {
    vm_exit!(vm, ip, NotATable);
}

#[cold]
unsafe fn invalid_table_key_error(ip: Ip, vm: Vm) -> Control {
    vm_exit!(vm, ip, InvalidTableKey);
}

#[inline(always)]
unsafe fn skeyc(vm: Vm, jt: Jt, ip: Ip, args: Skeyc, sp: Sp, lp: Lp) -> Control {
    let target = *sp.at(args.target());
    let key = lp.str_unchecked(args.key());
    let src = *sp.at(args.src());

    let ValueRaw::Table(table) = target else {
        return not_a_table_error(ip, vm);
    };

    // UNROOTED: reachable through the stack
    table.as_mut().insert_raw(key, src);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lnil(vm: Vm, jt: Jt, ip: Ip, args: Lnil, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Nil;

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lsmi(vm: Vm, jt: Jt, ip: Ip, args: Lsmi, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Int(args.v().get() as i64);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lint(vm: Vm, jt: Jt, ip: Ip, args: Lint, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Int(lp.int_unchecked(args.id()));

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lnum(vm: Vm, jt: Jt, ip: Ip, args: Lnum, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Float(lp.float_unchecked(args.id()));

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lstr(vm: Vm, jt: Jt, ip: Ip, args: Lstr, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn ltrue(vm: Vm, jt: Jt, ip: Ip, args: Ltrue, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Bool(true);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lfalse(vm: Vm, jt: Jt, ip: Ip, args: Lfalse, sp: Sp, lp: Lp) -> Control {
    *sp.at(args.dst()) = ValueRaw::Bool(false);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn lclosure(vm: Vm, jt: Jt, ip: Ip, args: Lclosure, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn lfunc(vm: Vm, jt: Jt, ip: Ip, args: Lfunc, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn llist(vm: Vm, jt: Jt, ip: Ip, args: Llist, sp: Sp, lp: Lp) -> Control {
    vm.maybe_gc();

    let len = args.cap().zx();

    // UNROOTED: immediately written to the stack
    let heap = vm.heap();
    let list = List::alloc_zeroed(&*heap, len);

    *sp.at(args.dst()) = ValueRaw::List(list);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn ltable(vm: Vm, jt: Jt, ip: Ip, args: Ltable, sp: Sp, lp: Lp) -> Control {
    vm.maybe_gc();

    let len = args.cap().zx();

    // UNROOTED: immediately written to the stack
    let heap = vm.heap();
    let table = Table::alloc(&*heap, len);

    *sp.at(args.dst()) = ValueRaw::Table(table);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn jmp(vm: Vm, jt: Jt, ip: Ip, args: Jmp, sp: Sp, lp: Lp) -> Control {
    let ip = ip.offset(args.rel().sz());

    dispatch_current(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn istrue(vm: Vm, jt: Jt, ip: Ip, args: Istrue, sp: Sp, lp: Lp) -> Control {
    // istrue v
    // jmp offset

    let v = *sp.at(args.v());
    if v.coerce_bool() {
        // skip `jmp`
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        // execute `jmp`
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn istruec(vm: Vm, jt: Jt, ip: Ip, args: Istruec, sp: Sp, lp: Lp) -> Control {
    // isfalsec dst, v
    // jmp offset

    let v = *sp.at(args.v());
    if v.coerce_bool() {
        // set `dst` to `v`
        *sp.at(args.dst()) = v;

        // skip `jmp`
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        // execute `jmp`
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isfalse(vm: Vm, jt: Jt, ip: Ip, args: Isfalse, sp: Sp, lp: Lp) -> Control {
    // isfalse v
    // jmp offset

    let v = *sp.at(args.v());
    if !v.coerce_bool() {
        // skip `jmp`
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        // execute `jmp`
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isfalsec(vm: Vm, jt: Jt, ip: Ip, args: Isfalsec, sp: Sp, lp: Lp) -> Control {
    // isfalsec dst, v
    // jmp offset

    let v = *sp.at(args.v());
    if !v.coerce_bool() {
        // set `dst` to `v`
        *sp.at(args.dst()) = v;

        // skip `jmp`
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        // execute `jmp`
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

macro_rules! try_cmp_eval {
    ($lhs:ident, $rhs:ident, $vm:ident, $ip:ident, $op:tt) => {{
        use ValueRaw::*;
        match ($lhs, $rhs) {
            // TODO: other types support comparisons too:
            //       nil, bool, str
            (Int(lhs), Int(rhs)) => lhs $op rhs,
            (Float(lhs), Float(rhs)) => lhs $op rhs,
            (Float(lhs), Int(rhs)) => lhs $op (rhs as f64),
            (Int(lhs), Float(rhs)) => (lhs as f64) $op rhs,
            _ => vm_exit!($vm, $ip, CmpTypeError),
        }
    }};
}

#[inline(always)]
unsafe fn islt(vm: Vm, jt: Jt, ip: Ip, args: Islt, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, <) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isle(vm: Vm, jt: Jt, ip: Ip, args: Isle, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, <=) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isgt(vm: Vm, jt: Jt, ip: Ip, args: Isgt, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, >) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isge(vm: Vm, jt: Jt, ip: Ip, args: Isge, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, >=) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn iseq(vm: Vm, jt: Jt, ip: Ip, args: Iseq, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, ==) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn isne(vm: Vm, jt: Jt, ip: Ip, args: Isne, sp: Sp, lp: Lp) -> Control {
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    if try_cmp_eval!(lhs, rhs, vm, ip, !=) {
        let ip = ip.offset(2);
        dispatch_current(vm, jt, ip, sp, lp)
    } else {
        let ip = ip.offset(1);
        dispatch_current(vm, jt, ip, sp, lp)
    }
}

#[inline(always)]
unsafe fn iseqs(vm: Vm, jt: Jt, ip: Ip, args: Iseqs, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isnes(vm: Vm, jt: Jt, ip: Ip, args: Isnes, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn iseqn(vm: Vm, jt: Jt, ip: Ip, args: Iseqn, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isnen(vm: Vm, jt: Jt, ip: Ip, args: Isnen, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn iseqp(vm: Vm, jt: Jt, ip: Ip, args: Iseqp, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isnep(vm: Vm, jt: Jt, ip: Ip, args: Isnep, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isltv(vm: Vm, jt: Jt, ip: Ip, args: Isltv, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn islev(vm: Vm, jt: Jt, ip: Ip, args: Islev, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isgtv(vm: Vm, jt: Jt, ip: Ip, args: Isgtv, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isgev(vm: Vm, jt: Jt, ip: Ip, args: Isgev, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn iseqv(vm: Vm, jt: Jt, ip: Ip, args: Iseqv, sp: Sp, lp: Lp) -> Control {
    todo!()
}

#[inline(always)]
unsafe fn isnev(vm: Vm, jt: Jt, ip: Ip, args: Isnev, sp: Sp, lp: Lp) -> Control {
    todo!()
}

macro_rules! try_arith_eval {
    ($dst:ident, $lhs:ident, $rhs:ident, $vm:ident, $ip:ident, $op:tt) => {
        use ValueRaw::*;
        match ($lhs, $rhs) {
            (Int(lhs), Int(rhs)) => {
                *$dst = Int(lhs $op rhs);
            }
            (Float(lhs), Float(rhs)) => {
                *$dst = Float(lhs $op rhs);
            }
            (Float(lhs), Int(rhs)) => {
                *$dst = Float(lhs $op (rhs as f64));
            }
            (Int(lhs), Float(rhs)) => {
                *$dst = Float((lhs as f64) $op rhs);
            }
            _ => {
                vm_exit!($vm, $ip, ArithTypeError);
            }
        }
    };
}

#[inline(always)]
unsafe fn addvv(vm: Vm, jt: Jt, ip: Ip, args: Addvv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, +);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn addvn(vm: Vm, jt: Jt, ip: Ip, args: Addvn, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = lp.int_or_float_unchecked(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, +);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn addnv(vm: Vm, jt: Jt, ip: Ip, args: Addnv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = lp.int_or_float_unchecked(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, +);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn subvv(vm: Vm, jt: Jt, ip: Ip, args: Subvv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, -);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn subvn(vm: Vm, jt: Jt, ip: Ip, args: Subvn, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = lp.int_or_float_unchecked(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, -);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn subnv(vm: Vm, jt: Jt, ip: Ip, args: Subnv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = lp.int_or_float_unchecked(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, -);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn mulvv(vm: Vm, jt: Jt, ip: Ip, args: Mulvv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, *);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn mulvn(vm: Vm, jt: Jt, ip: Ip, args: Mulvn, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = lp.int_or_float_unchecked(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, *);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn mulnv(vm: Vm, jt: Jt, ip: Ip, args: Mulnv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = lp.int_or_float_unchecked(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_arith_eval!(dst, lhs, rhs, vm, ip, *);

    dispatch_next(vm, jt, ip, sp, lp)
}

macro_rules! try_div_eval {
    ($dst:ident, $lhs:ident, $rhs:ident, $vm:ident, $ip:ident) => {
        use ValueRaw::*;
        match ($lhs, $rhs) {
            (Int(lhs), Int(rhs)) => match lhs.checked_div(rhs) {
                Some(v) => *$dst = Int(v),
                None => {
                    vm_exit!($vm, $ip, DivisionByZero)
                }
            },

            // float div by zero = inf
            (Float(lhs), Float(rhs)) => {
                *$dst = Float(lhs / rhs);
            }
            (Float(lhs), Int(rhs)) => {
                *$dst = Float(lhs / (rhs as f64));
            }
            (Int(lhs), Float(rhs)) => {
                *$dst = Float((lhs as f64) / rhs);
            }
            _ => {
                vm_exit!($vm, $ip, ArithTypeError);
            }
        }
    };
}

#[inline(always)]
unsafe fn divvv(vm: Vm, jt: Jt, ip: Ip, args: Divvv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_div_eval!(dst, lhs, rhs, vm, ip);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn divvn(vm: Vm, jt: Jt, ip: Ip, args: Divvn, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = *sp.at(args.lhs());
    let rhs = lp.int_or_float_unchecked(args.rhs());

    try_div_eval!(dst, lhs, rhs, vm, ip);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn divnv(vm: Vm, jt: Jt, ip: Ip, args: Divnv, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let lhs = lp.int_or_float_unchecked(args.lhs());
    let rhs = *sp.at(args.rhs());

    try_div_eval!(dst, lhs, rhs, vm, ip);

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn unm(vm: Vm, jt: Jt, ip: Ip, args: Unm, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let rhs = *sp.at(args.rhs());

    use ValueRaw::*;
    match rhs {
        Int(rhs) => {
            *dst = Int(-rhs);
        }
        ValueRaw::Float(rhs) => {
            *dst = Float(-rhs);
        }
        _ => {
            vm_exit!(vm, ip, ArithTypeError);
        }
    }

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn not(vm: Vm, jt: Jt, ip: Ip, args: Not, sp: Sp, lp: Lp) -> Control {
    let dst = sp.at(args.dst());
    let rhs = *sp.at(args.rhs());

    *dst = ValueRaw::Bool(!rhs.coerce_bool());

    dispatch_next(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn call(vm: Vm, jt: Jt, ip: Ip, args: Call, sp: Sp, lp: Lp) -> Control {
    // need closures before this can be implemented
    todo!()
}

#[inline(always)]
unsafe fn fastcall(vm: Vm, jt: Jt, ip: Ip, args: Fastcall, sp: Sp, lp: Lp) -> Control {
    let ret = args.dst();
    let callee = vm.get_function_in_current_module(args.id());

    let (sp, lp, ip) = do_call(callee, ret, ip, vm);

    dispatch_current(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn ret(vm: Vm, jt: Jt, ip: Ip, args: Ret, sp: Sp, lp: Lp) -> Control {
    let (sp, lp, ip) = return_from_call(vm);

    dispatch_current(vm, jt, ip, sp, lp)
}

#[inline(always)]
unsafe fn stop(vm: Vm, jt: Jt, ip: Ip, args: Stop, sp: Sp, lp: Lp) -> Control {
    Control::stop()
}

/// call procedure:
/// 1. grow stack if needed
/// 2. allocate new call frame
/// 3. jump to start of callee
///
/// new call frame's stack overlaps with the current frame's stack
/// example: assuming 3 args, with ret at r6:
/// ```text,ignore
///   frame N:   [ 0 1 2 3 4 5 6 7 8 9 ]
///                            ^ ^
///                            | args
///                            ret
///   frame N+1: [ 6 7 8 9 ... ]
///                ^ ^
///                | args
///                ret
/// ```
/// `r0` in the new frame will be in the same location as `r6`
/// in the previous frame.
#[inline(always)]
unsafe fn do_call(callee: Gc<FunctionProto>, ret: Reg, ip: Ip, vm: Vm) -> (Sp, Lp, Ip) {
    // See doc comment.
    let stack_base = vm.current_frame().stack_base() + (ret.get() as u32);

    // Return addr points to the next instruction after the call instruction.
    let current_function_start = Ip::from_fn(vm.current_frame().callee());
    let return_addr = 1 + (ip.offset_from_unsigned(current_function_start) as u32);

    let new_frame = CallFrame {
        callee,
        stack_base,
        return_addr,
    };

    let sp: Sp = maybe_grow_stack(vm, &new_frame);
    let lp: Lp = Lp::from_fn(new_frame.callee);
    let ip: Ip = Ip::from_fn(new_frame.callee);
    vm.set_current_module_for(callee);

    let prev_frame = core::ptr::replace(vm.current_frame().raw(), new_frame);
    vm.push_frame(prev_frame);

    (sp, lp, ip)
}

#[inline(always)]
unsafe fn maybe_grow_stack(vm: Vm, new_frame: &CallFrame) -> Sp {
    let new_stack_base = new_frame.stack_base as usize;
    let new_frame_size = new_frame.callee.as_ref().stack_size() as usize;
    if !vm.has_enough_stack_space(new_stack_base, new_frame_size) {
        grow_stack(vm, new_frame)
    }

    vm.stack_at(new_stack_base)
}

#[cold]
unsafe fn grow_stack(vm: Vm, new_frame: &CallFrame) {
    // NOTE: We allocate more than we need here, capacity doubles each time anyway.
    vm.grow_stack(new_frame.callee.as_ref().stack_size());
}

#[inline(always)]
unsafe fn return_from_call(vm: Vm) -> (Sp, Lp, Ip) {
    // Only called from `ret`, meaning we are guaranteed to have
    // at least the one call frame which is currently being executed.

    let returning_from = core::ptr::replace(vm.current_frame().raw(), vm.pop_frame_unchecked());
    let returning_to = vm.current_frame();

    let stack_base = returning_to.stack_base() as usize;
    let return_addr = returning_from.return_addr as usize;

    let sp: Sp = vm.stack_at(stack_base);
    let lp: Lp = Lp::from_fn(returning_to.callee());
    let ip: Ip = Ip::from_fn(returning_to.callee()).offset(return_addr as isize);
    vm.set_current_module_for(returning_to.callee());

    (sp, lp, ip)
}

type Invariant<'a> = PhantomData<fn(&'a ()) -> &'a ()>;

#[repr(C)]
pub struct Hebi {
    /// Boxed to guarantee address stability
    inner: Box<VmState>,
}

#[repr(align(16))]
pub(crate) struct VmState {
    /// Garbage collected heap
    heap: gc::Heap,

    /// Storage for loaded modules
    registry: ModuleRegistry,

    /// VM "registers"
    stack: DynArray<ValueRaw>,

    /// Invariant: Should never be empty.
    frames: DynStack<CallFrame>,

    /// Storage for the current call frame while the VM is executing.
    current_frame: Option<CallFrame>,

    /// When executing a function, we store the module it belongs to here,
    /// so that we can `fastcall` other functions from the same module.
    ///
    /// NOTE: This is always `Some` while the VM is executing
    current_module: Option<Gc<ModuleProto>>,

    /// Saved error.
    ///
    /// Used to avoid bloating size of instruction handler return value.
    error: Option<Error>,

    /// Saved instruction pointer.
    ///
    /// Used when the VM encounters an error, can be traced back to its
    /// associated span by the error handler.
    saved_ip: Option<Ip>,
}

impl Hebi {
    pub fn new() -> Self {
        // 1 MiB
        const INITIAL_STACK_SIZE: usize = (1024 * 1024) / std::mem::size_of::<ValueRaw>();
        const STACK_DEPTH: usize = INITIAL_STACK_SIZE / 16;

        Hebi {
            inner: Box::new(VmState {
                heap: gc::Heap::new(),
                registry: ModuleRegistry::new(),
                stack: DynArray::new(INITIAL_STACK_SIZE),
                frames: DynStack::new(STACK_DEPTH),

                current_module: None,
                error: None,
                saved_ip: None,
                current_frame: None,
            }),
        }
    }

    #[inline(always)]
    pub fn with<F>(&mut self, f: F)
    where
        F: for<'gc> FnOnce(Runtime<'gc>),
    {
        f(Runtime {
            vm: NonNull::from_mut(&mut *self.inner),
            _lifetime: PhantomData,
        })
    }
}

struct VmRoots {
    state: NonNull<VmState>,
}

impl gc::ExternalRoots for VmRoots {
    unsafe fn trace(&self, tracer: &gc::Tracer) {
        // note: call frame stack itself is not traced despite storing `Gc<FunctionProto>`,
        // because every function is also traced through the module registry.

        macro_rules! this {
            () => {
                *self.state.as_ptr()
            };
        }

        // iterate over VM stack
        let frames = &this!().frames;
        let sp = this!().stack.offset(0);
        for frame in this!().frames.iter() {
            let base = frame.stack_base as usize;
            let nstack = frame.callee.as_ref().stack_size();
            for i in base..base + nstack {
                tracer.visit_value(sp.add(i).read());
            }
        }

        // TODO: iterate over module registry
        for module in this!().registry.iter() {
            tracer.visit(module);
        }
    }
}

#[repr(transparent)]
pub struct Module<'vm> {
    inner: Gc<ModuleProto>,
    _lifetime: PhantomData<fn(&'vm ()) -> &'vm ()>,
}

pub struct Runtime<'vm> {
    vm: NonNull<VmState>,

    _lifetime: Invariant<'vm>,
}

// TODO: none of the public APIs should return `ValueRaw`.
// Currently they are kept alive by the fact that we only
// run gc during allocating instructions (`larr` and friends).
impl<'vm> Runtime<'vm> {
    /// Load a module into the VM's module registry.
    pub fn load(&mut self, m: &module::Module) -> Module<'vm> {
        let vm = unsafe { self.vm.as_mut() };
        let heap = &mut vm.heap;
        let registry = &mut vm.registry;
        let m = registry.add(heap, m);
        Module {
            inner: m,
            _lifetime: PhantomData,
        }
    }

    /// Execute the main entrypoint of the module to completion.
    ///
    /// Note that modules must go through [`Runtime::load`] first.
    pub fn run(&mut self, m: &Module<'vm>) -> Result<ValueRaw> {
        self.run_inner(m.inner)?;

        // SAFETY: Functions always store their return values in slot 0,
        // and are guaranteed to always allocate at least that slot.
        //
        // TODO: The resulting value is alive only because of implementation
        // details - we need to guarantee this _somehow_. Currently no GC happens
        // between the last `ret` and this point, and all stack values used
        // by the main entrypoint are guaranteed to not have been collected yet
        // until after its `ret`, at which point the stack frame is considered
        // dead.
        let vm = unsafe { self.vm.as_mut() };
        let value = unsafe { *vm.stack.offset(0) };
        Ok(value)
    }

    fn run_inner(&mut self, m: Gc<ModuleProto>) -> Result<()> {
        unsafe {
            self.vm.as_mut().current_frame = Some(CallFrame {
                callee: m.as_ref().entrypoint().as_ptr(),
                stack_base: 0,
                return_addr: 0,
            });
            self.vm.as_mut().current_module = Some(m);

            let vm: Vm = Vm(self.vm);
            let jt: Jt = JT.as_ptr();
            let sp: Sp = vm.stack_at(0);
            let lp: Lp = Lp::from_fn(vm.current_frame().callee());
            let ip: Ip = Ip::from_fn(vm.current_frame().callee());

            // In debug mode, fall back to loop+match.
            //
            // Each instruction will return `Control::Continue`
            // instead of tail-calling the next handler.
            #[cfg(debug_assertions)]
            {
                let mut sp: Sp = sp;
                let mut lp: Lp = lp;
                let mut ip: Ip = ip;

                loop {
                    let insn = ip.get();
                    let op = jt.at(insn);
                    match op(vm, jt, ip, insn, sp, lp) {
                        Control::Stop => return Ok(()),
                        Control::Error(err) if err.is_external() => {
                            let err = vm.take_error();
                            return Err(err.unwrap());
                        }
                        Control::Error(err) => return Err(err.annotate(vm)),

                        #[cfg(debug_assertions)]
                        Control::Continue(new_sp, new_lp, new_ip) => {
                            sp = new_sp;
                            lp = new_lp;
                            ip = new_ip;
                            continue;
                        }
                    }
                }
            }

            #[cfg(not(debug_assertions))]
            {
                let ctrl = dispatch_current(vm, jt, ip, sp, lp);

                if ctrl.is_error() {
                    let err = ctrl.error_code();
                    if err.is_external() {
                        let err = vm.take_error();
                        return Err(err.unwrap());
                    } else {
                        return Err(err.annotate(vm));
                    }
                }

                return Ok(());
            }
        }
    }

    pub fn fmt(&self, value: ValueRaw) -> impl std::fmt::Display + '_ {
        struct ValueFormatter<'a, 'gc> {
            this: &'a Runtime<'gc>,
            value: ValueRaw,
        }

        impl<'gc> std::fmt::Display for ValueFormatter<'_, 'gc> {
            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
                match self.value {
                    ValueRaw::Nil => write!(f, "nil"),
                    ValueRaw::Bool(v) => write!(f, "{v}"),
                    ValueRaw::Int(v) => write!(f, "{v}"),
                    ValueRaw::Float(v) => write!(f, "{v}"),
                    ValueRaw::String(v) => {
                        let str = unsafe { v.as_ref() };
                        write!(f, "{}", str.as_str())
                    }
                    ValueRaw::List(v) => {
                        let list = unsafe { v.as_ref() };

                        write!(f, "[")?;
                        let mut comma = false;
                        for item in list {
                            if comma {
                                write!(f, ", ")?;
                            }
                            write!(
                                f,
                                "{}",
                                ValueFormatter {
                                    this: self.this,
                                    value: item.raw(),
                                }
                            )?;
                            comma = true;
                        }
                        write!(f, "]")?;

                        Ok(())
                    }
                    ValueRaw::Table(v) => {
                        let table = unsafe { v.as_ref() };

                        write!(f, "{{")?;
                        let mut comma = false;
                        for (key, value) in table {
                            if comma {
                                write!(f, ", ")?;
                            }
                            write!(
                                f,
                                "{}={}",
                                key.as_str(),
                                ValueFormatter {
                                    this: self.this,
                                    value: value.raw(),
                                }
                            )?;
                            comma = true;
                        }
                        write!(f, "}}")?;

                        Ok(())
                    }
                    ValueRaw::UserData(v) => {
                        todo!()
                    }
                }
            }
        }

        ValueFormatter { this: self, value }
    }
}

#[cfg(test)]
mod tests;
